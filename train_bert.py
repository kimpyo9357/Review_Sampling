import pandas as pd
import urllib.request
from wordcloud import STOPWORDS

#urllib.request.urlretrieve("https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt", filename="ratings_train.txt")
#urllib.request.urlretrieve("https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt", filename="ratings_test.txt")

train_data = pd.read_table('ratings_train.txt')
test_data = pd.read_table('ratings_test.txt')

comment_words = ''
stopwords = set(STOPWORDS)
tokenized_text = []

'''# 3. ë¬¸ì¥ ë°ì´í„°ë¥¼ ë‹¨ì–´í™”í•˜ê¸°
for val in train_data["document"]:

  # ë¬¸ì¥ì„ stringìœ¼ë¡œ ë§Œë“¤ê¸°
  val = str(val)

  # ë¬¸ì¥ì„ ìª¼ê°œê¸°
  tokens = val.split()

  tokenized_text.append(tokens)
  comment_words += " ".join(tokens) + " "


stopwords_2 = ["ì˜í™”", "ì§„ì§œ", "ì •ë§", "ì´ê±°", "ê·¸ëƒ¥", "ë„ˆë¬´", "ì˜í™”ê°€", "ì˜í™”ëŠ”",
             "ì´ê±°", "ì´ê²Œ", "ì´ê±´", "ì˜í™”ì˜", "ì–´ë–¤", "ì•„ì£¼", "ê³„ì†", "ì˜í™”ë‹¤",
             "ì˜í™”ë¥¼", "ê·¸ë¦¬ê³ "
]


def filter_stopwords(tokenized_text, stopwords_2):
  tokenized_filtered = []

  for i in tokenized_text:
    for word in i:
      if word not in stopwords and word not in stopwords_2:
        tokenized_filtered.append(word)

  return tokenized_filtered

import operator


def word_count(tokenized_data):
  word_counter = {}

  for i in tokenized_data:
    if i in word_counter.keys():
      word_counter[i] += 1
    else:
      word_counter[i] = 1

  # ë§ì´ ë‚˜ì˜¨ ìˆœì„œëŒ€ë¡œ ì •ë ¬

  sorted_dict = dict(sorted(word_counter.items(),
                            key=operator.itemgetter(1), reverse=True))

  return sorted_dict

def top_20(tokenized_dict):
  top_20_words = list(tokenized_dict.items())[:20]
  return top_20_words

stopwords_2.extend(["ì´", "ì´ë ‡ê²Œ", "ë”", "ìˆ˜", "ë‹¤", "ê·¸", "ë‚´ê°€", "ì´ë ‡ê²Œ",
               "ì™„ì „", "ë´¤ëŠ”ë°", "ì˜í™”.", "í‰ì ", "í‰ì ì´", "ì™œ", "ì´ëŸ°", "ë³¸",
               "ë³´ê³ ", "ì˜"
])

stopwords_2.extend(["ë³´ëŠ”", "ë‚´", "ë‹¤ì‹œ", "ë‚œ", "ì—°ê¸°", "í•œ", "ê²ƒ", "í•˜ëŠ”", "ë˜",
                    "ì—­ì‹œ", "ì¢€", "ì°¸", "ë§ì´", "ì—†ëŠ”", "ìˆëŠ”"
])

tokenized_filtered = filter_stopwords(tokenized_text, stopwords_2)
tokenized_dict = word_count(tokenized_filtered)

#print(top_20(tokenized_dict))

emotion_dict = {"ìµœê³ ì˜": "ê·¹ì°¬", "ã…‹ã…‹": "ì›ƒìŒ", "ì¢‹ì€": "ê¸°ì¨", "ì¬ë°Œê²Œ": "í¥ë¯¸",
                "ì“°ë ˆê¸°": "í˜ì˜¤", "ã…‹ã…‹ã…‹": "ì›ƒìŒ", "ã…‹": "ë¬´ì‹¬", "ã… ã… ": "ìŠ¬í””"
}

from collections import defaultdict, OrderedDict

emotions_dict = defaultdict(int)

emotions_list = []

for k, v in tokenized_dict.items():
  for key, value in emotion_dict.items():
    if k == key:
      emotions_list.append((value, v))

for k, v in emotions_list:
  if k in emotions_dict:
    emotions_dict[k] += v
  else:
    emotions_dict[k] = v

emotions_dict = OrderedDict(sorted(emotions_dict.items(),
                            key=lambda item: item[1],
                            reverse=True))
'''
import torch

from transformers import BertTokenizer
from transformers import BertForSequenceClassification, AdamW, Adafactor, BertConfig
from transformers import get_linear_schedule_with_warmup
from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler
from keras.utils import pad_sequences
#from keras.preprocessing.sequence import pad_sequences
from sklearn.model_selection import train_test_split

import pandas as pd
import numpy as np
import random
import time
import os
import datetime


from PyKomoran import *
komoran = Komoran("EXP")

os.makedirs(f'./saved_models', exist_ok=True)

##train í† í°í™”
train_data_values = train_data['label'].values[:100]
test_data_values = test_data["label"].values[:100]

tokenized_data = []
count = 0
#for i in range(len(train_data['document'])):
for i in range(0,100):
  try:
    print(str(i) +"/"+str(len(train_data['document'])))
    temp = komoran.get_plain_text(train_data['document'][i])
    bert = temp.split()
    for j in range(len(bert)):
      bert[j] = bert[j].split("/")[0]
    bert.insert(0,"[CLS]")
    bert.append("[SEP]")
    tokenized_data.append(bert)
  except:
    train_data_values = np.delete(train_data_values, i-count)
    count += 1
    print("pass")
    continue

##test í† í°í™”
tokenized_test_data = []
count = 0
for i in range(0,100):
  try:
    print(str(i) +"/"+str(len(test_data['document'])))
    temp = komoran.get_plain_text(test_data['document'][i])
    bert = temp.split()
    for j in range(len(bert)):
      bert[j] = bert[j].split("/")[0]
    bert.insert(0,"[CLS]")
    bert.append("[SEP]")
    tokenized_test_data.append(bert)
  except:
    test_data_values = np.delete(test_data_values, i-count)
    count += 1
    print("pass")
    continue

#print(test_data_values)
#ì „ì²˜ë¦¬
################################################################################################################
#BERT í•™ìŠµ
tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)
# padding
#input_ids = []
'''for i in tokenized_data:
  ids = tokenizer.convert_tokens_to_ids(i)
  input_ids.append(ids)'''

#print(input_ids)

input_ids_test = []
for i in tokenized_test_data:
  ids = tokenizer.convert_tokens_to_ids(i)
  input_ids_test.append(ids)

max_len = 128
#input_ids = pad_sequences(input_ids, maxlen=max_len, dtype='long', truncating='post', padding='post')
input_ids_test = pad_sequences(input_ids_test, maxlen=max_len, dtype='long', truncating='post', padding='post')

attention_masks = []

'''for ids in input_ids:
  ids_mask = []
  for id in ids:
    masked = float(id > 0)
    ids_mask.append(masked)
  attention_masks.append(ids_mask)'''

attention_masks_test = []

for ids in input_ids_test:
  ids_mask = []
  for id in ids:
      masked = float(id>0)
      ids_mask.append(masked)
  attention_masks_test.append(ids_mask)


'''X_train, X_val, y_train, y_val = train_test_split(
    input_ids, train_data_values, random_state=42, test_size=0.2)'''

'''print(X_train)
print("------------------------------------------------")
print(X_val)
print("------------------------------------------------")
print(y_train)
print("------------------------------------------------")
print(y_val)
print("------------------------------------------------")'''


#train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids, random_state=42, test_size=0.2)

'''print(train_masks)
print("------------------------------------------------")
print(validation_masks)
print("------------------------------------------------")

X_train_tune = X_train
y_train_tune = y_train
X_val_tune = X_val
y_val_tune = y_val'''

X_test_tensor = input_ids_test
y_test_tensor = test_data_values
test_masks = attention_masks_test

'''# PyTorchë¡œ ë³€í™˜
X_train_tensor = torch.tensor(X_train)
y_train_tensor = torch.tensor(y_train)
train_masks = torch.tensor(train_masks)
X_val_tensor = torch.tensor(X_val)
y_val_tensor = torch.tensor(y_val)
validation_masks = torch.tensor(validation_masks)'''

X_test_tensor = torch.tensor(X_test_tensor)
y_test_tensor = torch.tensor(y_test_tensor)
test_masks = torch.tensor(attention_masks_test)

batch_size = 32
'''
train = TensorDataset(X_train_tensor, train_masks, y_train_tensor)
train_sampler = RandomSampler(train)

val = TensorDataset(X_val_tensor, validation_masks, y_val_tensor)
val_sampler = SequentialSampler(val)
'''

test = TensorDataset(X_test_tensor, test_masks, y_test_tensor)
test_sampler = RandomSampler(test)

'''train_dataloader = DataLoader(train, sampler=train_sampler, batch_size=batch_size)
val_dataloader = DataLoader(val, sampler=val_sampler, batch_size=batch_size)'''
test_dataloader = DataLoader(test, sampler=test_sampler, batch_size=batch_size)

if torch.cuda.is_available():
    device = torch.device("cuda")
    print('There are %d GPU(s) available.' % torch.cuda.device_count())
    print('We will use the GPU:', torch.cuda.get_device_name(0))
else:
    device = torch.device("cpu")
    print('No GPU available, using the CPU instead.')

model = BertForSequenceClassification.from_pretrained("bert-base-multilingual-cased", num_labels=2)
model.cuda()

for param in model.base_model.parameters():
    param.requires_grad = False

from sklearn.model_selection import train_test_split

train_queries, val_queries, train_docs, val_docs, train_labels, val_labels = train_test_split(
  train_data["id"].apply(str).tolist(),
  train_data["document"].apply(str).tolist(),
  train_data["label"].tolist(),
  test_size=.2
)

from transformers import BertTokenizerFast

model_name = "bert-base-multilingual-cased"
tokenizer = BertTokenizerFast.from_pretrained(model_name)

train_encodings = tokenizer(train_queries, train_docs, truncation=True, padding='max_length', max_length=max_len)
val_encodings = tokenizer(val_queries, val_docs, truncation=True, padding='max_length', max_length=max_len)

import torch

class Cord19Dataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.labels)
'''
train_dataset = Cord19Dataset(train_encodings, train_labels)
val_dataset = Cord19Dataset(val_encodings, val_labels)

from transformers import Trainer, TrainingArguments

t raining_args = TrainingArguments(
    output_dir='./',          # output directory
    evaluation_strategy="epoch",     # Evaluation is done at the end of each epoch.
    num_train_epochs=3,              # total number of training epochs
    per_device_train_batch_size=32,  # batch size per device during training
    per_device_eval_batch_size=32,   # batch size for evaluation
    warmup_steps=0,                # number of warmup steps for learning rate scheduler
    weight_decay=0,               # strength of weight decay
    save_total_limit=1,              # limit the total amount of checkpoints. Deletes the older checkpoints.
)

trainer = Trainer(
    model=model,                         # the instantiated ğŸ¤— Transformers model to be trained
    args=training_args,                  # training arguments, defined above
    train_dataset=train_dataset,         # training dataset
    eval_dataset=val_dataset             # evaluation dataset
)

trainer.train()
'''
# ì˜µí‹°ë§ˆì´ì € ì„¤ì •
optimizer = AdamW(model.parameters(),
                  lr=1e-5,  # í•™ìŠµë¥ 
                  eps=1e-8  # 0ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ê²ƒì„ ë°©ì§€í•˜ê¸° ìœ„í•œ epsilon ê°’,
                  )
# ì—í­ìˆ˜
epochs = 30

# ì´ í›ˆë ¨ ìŠ¤í…
#total_steps = len(train_dataloader) * epochs

# Learning rate decayë¥¼ ìœ„í•œ ìŠ¤ì¼€ì¤„ëŸ¬
'''scheduler = get_linear_schedule_with_warmup(optimizer,
                                            num_warmup_steps=0,
                                            num_training_steps=total_steps)'''

# ì •í™•ë„ ê³„ì‚° í•¨ìˆ˜
def accuracy_measure(y_pred, y):
    pred_flattened = np.argmax(y_pred, axis=1).flatten()
    print(pred_flattened)
    y_flattened = y.flatten()
    return np.sum(pred_flattened == y_flattened) / len(y_flattened)

# ì‹œê°„ í‘œì‹œ í•¨ìˆ˜
def time_elapsed(elapsed):
    # ë°˜ì˜¬ë¦¼
    elapsed = int(round((elapsed)))
    # hh:mm:ssìœ¼ë¡œ í˜•íƒœ ë³€ê²½
    return str(datetime.timedelta(seconds=elapsed))

# ì¬í˜„ì„ ìœ„í•´ ëœë¤ì‹œë“œ ê³ ì •
seed_val = 42
random.seed(seed_val)
np.random.seed(seed_val)
torch.manual_seed(seed_val)
torch.cuda.manual_seed_all(seed_val)

# ê·¸ë˜ë””ì–¸íŠ¸ ì´ˆê¸°í™”
model.zero_grad()

'''
best_accuracy = 0
# ë³¸ê²©ì ì¸ í•™ìŠµ
for epoch_i in range(0, epochs):

    # ========================================
    #                            Training
    # ========================================

    # í˜„ì¬ í›ˆë ¨ ì¡°ê±´ í‘œì‹œ
    print("")
    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))
    print('Training...')

    # ì‹œì‘ ì‹œê°„ ì„¤ì •
    t0 = time.time()

    # ë¡œìŠ¤ ì´ˆê¸°í™”
    total_loss = 0

    # í›ˆë ¨ëª¨ë“œë¡œ ë³€ê²½
    model.train()

    # ë°ì´í„°ë¡œë”ì—ì„œ ë°°ì¹˜ë§Œí¼ ë°˜ë³µí•˜ì—¬ ê°€ì ¸ì˜´
    for step, batch in enumerate(train_dataloader):
        # ê²½ê³¼ ì •ë³´ í‘œì‹œ
        if step % 500 == 0 and not step == 0:
            elapsed = time_elapsed(time.time() - t0)
            print(' Batch {:>5,}    of  {:>5,}.     Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))

        # ë°°ì¹˜ë¥¼ GPUì— ë„£ìŒ
        batch = tuple(t.to(device) for t in batch)

        # ë°°ì¹˜ì—ì„œ ë°ì´í„° ì¶”ì¶œ
        b_input_ids, b_input_mask, b_labels = batch

        # Forward ìˆ˜í–‰
        outputs = model(b_input_ids,
                                        token_type_ids=None,
                                        attention_mask=b_input_mask,
                                        labels=b_labels)

        # ë¡œìŠ¤ êµ¬í•¨
        loss = outputs[0]
        # ì´ ë¡œìŠ¤ ê³„ì‚°
        total_loss += loss.item()
        # Backward ìˆ˜í–‰ìœ¼ë¡œ ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°
        loss.backward()
        # ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘
        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
        # ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ í†µí•´ ê°€ì¤‘ì¹˜ íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸
        optimizer.step()
        # ìŠ¤ì¼€ì¤„ëŸ¬ë¡œ í•™ìŠµë¥  ê°ì†Œ
        scheduler.step()
        # ê·¸ë˜ë””ì–¸íŠ¸ ì´ˆê¸°í™”
        model.zero_grad()

    # í‰ê·  ë¡œìŠ¤ ê³„ì‚°
    avg_train_loss = total_loss / len(train_dataloader)

    print("")
    print(" Average training loss: {0:.2f}".format(avg_train_loss))
    print(" Training epcoh took: {:}".format(time_elapsed(time.time() - t0)))
    # ========================================
    #                            Validation
    # ========================================

    print("")
    print("Running Validation...")

    # ì‹œì‘ ì‹œê°„ ì„¤ì •
    t0 = time.time()

    # í‰ê°€ëª¨ë“œë¡œ ë³€ê²½
    model.eval()

    # ë³€ìˆ˜ ì´ˆê¸°í™”
    eval_loss, eval_accuracy = 0, 0
    nb_eval_steps, nb_eval_examples = 0, 0

    # ë°ì´í„°ë¡œë”ì—ì„œ ë°°ì¹˜ë§Œí¼ ë°˜ë³µí•˜ì—¬ ê°€ì ¸ì˜´
    for batch in val_dataloader:
        # ë°°ì¹˜ë¥¼ GPUì— ë„£ìŒ
        batch = tuple(t.to(device) for t in batch)

        # ë°°ì¹˜ì—ì„œ ë°ì´í„° ì¶”ì¶œ
        b_input_ids, b_input_mask, b_labels = batch

        # ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚° ì•ˆí•¨
        with torch.no_grad():
            # Forward ìˆ˜í–‰
            outputs = model(b_input_ids,
                                            token_type_ids=None,
                                            attention_mask=b_input_mask)

            # ë¡œìŠ¤ êµ¬í•¨
            logits = outputs[0]

            # CPUë¡œ ë°ì´í„° ì´ë™
            logits = logits.detach().cpu().numpy()
            label_ids = b_labels.to('cpu').numpy()

            # ì¶œë ¥ ë¡œì§“ê³¼ ë¼ë²¨ì„ ë¹„êµí•˜ì—¬ ì •í™•ë„ ê³„ì‚°
            tmp_eval_accuracy = accuracy_measure(logits, label_ids)
            eval_accuracy += tmp_eval_accuracy
            nb_eval_steps += 1

    if eval_accuracy > best_accuracy:
            best_accuracy = eval_accuracy
            torch.save(model.state_dict(), f'./saved_models/best_accuracy.pth')
    torch.save(model.state_dict(), f'./saved_models/iter_{epoch_i +1}.pth')
    print(" Accuracy: {0:.2f}".format(eval_accuracy / nb_eval_steps))
    print(" Best_Accuracy: {0:.2f}".format(best_accuracy / nb_eval_steps))
    print(" Validation took: {:}".format(time_elapsed(time.time() - t0)))

print("")
print("Training complete!")
'''
# ì‹œì‘ ì‹œê°„ ì„¤ì •
t0 = time.time()

# í‰ê°€ëª¨ë“œë¡œ ë³€ê²½
model.eval()

# ë³€ìˆ˜ ì´ˆê¸°í™”
eval_loss, eval_accuracy = 0, 0
nb_eval_steps, nb_eval_examples = 0, 0

# ë°ì´í„°ë¡œë”ì—ì„œ ë°°ì¹˜ë§Œí¼ ë°˜ë³µí•˜ì—¬ ê°€ì ¸ì˜´
for step, batch in enumerate(test_dataloader):
    # ê²½ê³¼ ì •ë³´ í‘œì‹œ
    if step % 100 == 0 and not step == 0:
        elapsed = time_elapsed(time.time() - t0)
        print(' Batch {:>5,}    of  {:>5,}.     Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))

    # ë°°ì¹˜ë¥¼ GPUì— ë„£ìŒ
    batch = tuple(t.to(device) for t in batch)

    # ë°°ì¹˜ì—ì„œ ë°ì´í„° ì¶”ì¶œ
    b_input_ids, b_input_mask, b_labels = batch

    # ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚° ì•ˆí•¨
    with torch.no_grad():
        # Forward ìˆ˜í–‰
        outputs = model(b_input_ids,
                                        token_type_ids=None,
                                        attention_mask=b_input_mask)

    # ë¡œìŠ¤ êµ¬í•¨
    logits = outputs[0]

    # CPUë¡œ ë°ì´í„° ì´ë™
    logits = logits.detach().cpu().numpy()
    label_ids = b_labels.to('cpu').numpy()

    # ì¶œë ¥ ë¡œì§“ê³¼ ë¼ë²¨ì„ ë¹„êµí•˜ì—¬ ì •í™•ë„ ê³„ì‚°
    tmp_eval_accuracy = accuracy_measure(logits, label_ids)
    eval_accuracy += tmp_eval_accuracy
    nb_eval_steps += 1


print("")
print("Accuracy: {0:.2f}".format(eval_accuracy / nb_eval_steps))
print("Test took: {:}".format(time_elapsed(time.time() - t0)))